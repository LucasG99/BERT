# ğŸ¤– Twitter Bot Detection com TinyBERT

Este projeto tem como objetivo treinar uma rede neural baseada em **TinyBERT** utilizando **Keras** para detectar contas automatizadas (bots) no Twitter.  
A implementaÃ§Ã£o foi feita no **Google Colab** com base no dataset **Twitter Bot Detection** disponÃ­vel no Kaggle.

---

## ğŸ“‚ Estrutura do Projeto

- `bot_detection_data.csv` â†’ Dataset utilizado (tweets e rÃ³tulo indicando se Ã© bot ou humano).  
- `notebook.ipynb` â†’ Notebook com todo o pipeline (prÃ©-processamento, treino, avaliaÃ§Ã£o e grÃ¡ficos).  
- `TinyBERT_trained.zip` â†’ Modelo TinyBERT treinado e salvo, pronto para reutilizaÃ§Ã£o.  
- `README.md` â†’ Este arquivo de documentaÃ§Ã£o.  

---

## âš™ï¸ Tecnologias Utilizadas

- **Python 3**  
- [TensorFlow](https://www.tensorflow.org/)  
- [Transformers (Hugging Face)](https://huggingface.co/transformers/)  
- **Pandas / Numpy / Scikit-learn**  
- **Matplotlib / Seaborn**  

---

## ğŸš€ Como Rodar o Projeto

1. Clone este repositÃ³rio:
   ```bash
   git clone https://github.com/seuusuario/twitter-bot-detection.git
   cd twitter-bot-detection

Abra o notebook no Google Colab ou em ambiente local.
Certifique-se de ter GPU habilitada, se possÃ­vel.

Instale as dependÃªncias:

pip install tensorflow transformers scikit-learn matplotlib seaborn pandas

Execute o notebook passo a passo.

ğŸ“Š Resultados

AcurÃ¡cia no conjunto de teste: ~0.50

Matriz de ConfusÃ£o: o modelo classificou todas as amostras como "Humano", nÃ£o identificando bots.

Curva ROC e AUC: ~0.51, indicando desempenho prÃ³ximo ao acaso.

Curvas de Perda: estÃ¡veis em torno de 0.693, mostrando que o modelo nÃ£o aprendeu padrÃµes relevantes.

Exemplos de GrÃ¡ficos

Matriz de ConfusÃ£o
Mostrou que o modelo nÃ£o conseguiu separar as classes.

Curva ROC
Linha prÃ³xima da diagonal, AUC â‰ˆ 0.51.

Curva de Perda
Estagnada, sem indÃ­cios de aprendizado.

ğŸ“Œ LiÃ§Ãµes Aprendidas

Durante o desenvolvimento deste projeto, percebi que:

Trabalhar com modelos da famÃ­lia BERT exige muito mais do que apenas rodar cÃ³digo pronto: Ã© necessÃ¡rio ajuste fino, balanceamento de classes e maior tempo de treino.

Nem sempre usar um modelo de ponta garante bons resultados se o dataset ou a configuraÃ§Ã£o nÃ£o forem adequados.

Resultados ruins tambÃ©m tÃªm valor: eles mostram limitaÃ§Ãµes e apontam os prÃ³ximos passos para evoluÃ§Ã£o do projeto.
